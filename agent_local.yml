# Rebrew Local Model Agent â€” Configuration
# This file configures the autonomous agent that uses a local LLM
# to reverse-engineer functions from your target binary.

llm:
  api_base: "http://localhost:8000/v1"      # Any OpenAI-compatible endpoint
  model: "qwen3-coder-next"                 # Model name as served
  api_key: "not-needed"                     # Most local servers don't need this
  temperature: 0.2
  max_tokens: 4096
  timeout: 120                              # Seconds per LLM request

agent:
  max_functions: 50                         # Max functions to attempt per run
  max_retries: 3                            # LLM retries per function
  smallest_first: true                      # Process by size ascending
  min_size: 10                              # Skip functions smaller than this
  max_size: 2000                            # Skip functions larger than this

logging:
  audit_dir: "reports/audit"                # Every prompt/response pair
  report_dir: "reports"                     # Run reports
  verbose: false                            # Print prompts to terminal
